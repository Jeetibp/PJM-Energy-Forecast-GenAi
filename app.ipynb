{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121c7021-0ca2-4c9b-8398-9b15b0c88900",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed7f510-95d1-44d9-9eac-2525888c4920",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6b9b88c9-5d21-4359-9436-ed5168a629a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-15 22:18:47.821 No runtime found, using MemoryCacheStorageManager\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeltaGenerator()"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pickle\n",
    "from datetime import datetime, timedelta\n",
    "import plotly.graph_objects as go\n",
    "from huggingface_hub import InferenceClient\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "st.set_page_config(page_title=\"PJM Forecast & GenAI\", page_icon=\"âš¡\", layout=\"wide\")\n",
    "\n",
    "# --- Load Model & Metadata ---\n",
    "@st.cache_resource\n",
    "def load_xgb_and_meta():\n",
    "    try:\n",
    "        model = joblib.load(\"models/xgboost_model.pkl\")\n",
    "        with open(\"models/metadata.pkl\", \"rb\") as f:\n",
    "            meta = pickle.load(f)\n",
    "        return model, meta, None\n",
    "    except Exception as e:\n",
    "        return None, None, str(e)\n",
    "\n",
    "xgb_model, meta, load_error = load_xgb_and_meta()\n",
    "if meta:\n",
    "    feature_cols = meta.get(\"feature_columns\", [])\n",
    "    perf = meta.get(\"model_performance\", {}).get(\"XGBoost\", {})\n",
    "    default_mape = perf.get('MAPE', 1.0)\n",
    "else:\n",
    "    feature_cols = []\n",
    "    perf = {}\n",
    "    default_mape = 1.0\n",
    "\n",
    "# --- Helper Functions ---\n",
    "def add_confidence_intervals(df, mape):\n",
    "    df['lower'] = df['predicted_consumption'] * (1 - mape/100)\n",
    "    df['upper'] = df['predicted_consumption'] * (1 + mape/100)\n",
    "    return df\n",
    "\n",
    "def create_features_for_prediction(dt, lag_vals):\n",
    "    hour = dt.hour\n",
    "    day_of_week = dt.weekday()\n",
    "    month = dt.month\n",
    "    year = dt.year\n",
    "    quarter = (month - 1) // 3 + 1\n",
    "    is_weekend = 1 if day_of_week >= 5 else 0\n",
    "    season_map = {12: 0, 1: 0, 2: 0, 3: 1, 4: 1, 5: 1, 6: 2, 7: 2, 8: 2, 9: 3, 10: 3, 11: 3}\n",
    "    season = season_map[month]\n",
    "    hour_sin = np.sin(2 * np.pi * hour / 24)\n",
    "    hour_cos = np.cos(2 * np.pi * hour / 24)\n",
    "    month_sin = np.sin(2 * np.pi * month / 12)\n",
    "    month_cos = np.cos(2 * np.pi * month / 12)\n",
    "    features = {\n",
    "        'hour': hour,\n",
    "        'day_of_week': day_of_week,\n",
    "        'month': month,\n",
    "        'year': year,\n",
    "        'quarter': quarter,\n",
    "        'is_weekend': is_weekend,\n",
    "        'season': season,\n",
    "        'hour_sin': hour_sin,\n",
    "        'hour_cos': hour_cos,\n",
    "        'month_sin': month_sin,\n",
    "        'month_cos': month_cos,\n",
    "        'lag_1h': lag_vals.get('lag_1h', 5600),\n",
    "        'lag_24h': lag_vals.get('lag_24h', 5600),\n",
    "        'lag_168h': lag_vals.get('lag_168h', 5600),\n",
    "        'rolling_mean_24h': lag_vals.get('rolling_mean_24h', 5600),\n",
    "        'rolling_std_24h': lag_vals.get('rolling_std_24h', 1000)\n",
    "    }\n",
    "    return pd.DataFrame([features])[feature_cols]\n",
    "\n",
    "def generate_30_day_forecast(model, start_date, initial_lag, mape_adj=1.0, demand_shift=0):\n",
    "    forecasts = []\n",
    "    current_dt = start_date\n",
    "    recent = [initial_lag['lag_1h']] * 168\n",
    "    for _ in range(30 * 24):\n",
    "        lag_vals = {\n",
    "            'lag_1h': recent[-1] if len(recent) >= 1 else 5600,\n",
    "            'lag_24h': recent[-24] if len(recent) >= 24 else 5600,\n",
    "            'lag_168h': recent[-168] if len(recent) >= 168 else 5600,\n",
    "            'rolling_mean_24h': np.mean(recent[-24:]) if len(recent) >= 24 else 5600,\n",
    "            'rolling_std_24h': np.std(recent[-24:]) if len(recent) >= 24 else 1000\n",
    "        }\n",
    "        features = create_features_for_prediction(current_dt, lag_vals)\n",
    "        pred = model.predict(features)[0] + demand_shift\n",
    "        forecasts.append({'datetime': current_dt, 'predicted_consumption': pred})\n",
    "        recent.append(pred)\n",
    "        if len(recent) > 168:\n",
    "            recent = recent[-168:]\n",
    "        current_dt += timedelta(hours=1)\n",
    "    df = pd.DataFrame(forecasts)\n",
    "    df = add_confidence_intervals(df, mape_adj)\n",
    "    return df\n",
    "\n",
    "def generate_peak_table(df):\n",
    "    peak_hours = df.sort_values('predicted_consumption', ascending=False).head(5)\n",
    "    peak_hours = peak_hours[['datetime', 'predicted_consumption', 'upper', 'lower']]\n",
    "    peak_hours.columns = ['DateTime', 'Predicted MW', 'Upper Bound', 'Lower Bound']\n",
    "    return peak_hours\n",
    "\n",
    "def generate_automated_insights(df, mape):\n",
    "    max_row = df.loc[df['predicted_consumption'].idxmax()]\n",
    "    min_row = df.loc[df['predicted_consumption'].idxmin()]\n",
    "    avg = df['predicted_consumption'].mean()\n",
    "    return (\n",
    "        f\"â€¢ **Peak demand** is expected on **{max_row['datetime'].strftime('%Y-%m-%d %H:%M')}** at **{max_row['predicted_consumption']:.1f} MW**.\\n\"\n",
    "        f\"â€¢ **Lowest demand** is expected on **{min_row['datetime'].strftime('%Y-%m-%d %H:%M')}** at **{min_row['predicted_consumption']:.1f} MW**.\\n\"\n",
    "        f\"â€¢ **Average demand** over 30 days is **{avg:.1f} MW**.\\n\"\n",
    "        f\"â€¢ 95% of predictions are expected to be within Â±{mape:.2f}% of the forecasted value.\"\n",
    "    )\n",
    "\n",
    "def generate_report_text(df, perf, mape):\n",
    "    max_row = df.loc[df['predicted_consumption'].idxmax()]\n",
    "    min_row = df.loc[df['predicted_consumption'].idxmin()]\n",
    "    avg = df['predicted_consumption'].mean()\n",
    "    total = df['predicted_consumption'].sum() / 1000\n",
    "    lines = [\n",
    "        \"PJM 30-Day Energy Forecast Report\",\n",
    "        \"=\"*35,\n",
    "        f\"Forecast Start: {df['datetime'].iloc[0]}\",\n",
    "        f\"Forecast End:   {df['datetime'].iloc[-1]}\",\n",
    "        \"\",\n",
    "        f\"Peak Demand: {max_row['predicted_consumption']:.1f} MW at {max_row['datetime']}\",\n",
    "        f\"Lowest Demand: {min_row['predicted_consumption']:.1f} MW at {min_row['datetime']}\",\n",
    "        f\"Average Demand: {avg:.1f} MW\",\n",
    "        f\"Total Energy: {total:.1f} GWh\",\n",
    "        f\"Model: XGBoost (MAPE: {mape:.2f}%)\",\n",
    "        \"\",\n",
    "        \"Forecast Table (first 10 rows):\",\n",
    "        df.head(10).to_string(index=False)\n",
    "    ]\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# --- GenAI (Llama-3) for Q&A and Report ---\n",
    "def ask_hf_llm(question, df, colname='predicted_consumption'):\n",
    "    HF_TOKEN = st.secrets[\"hf_token\"][\"hf_token\"]\n",
    "    client = InferenceClient(\"meta-llama/Meta-Llama-3-70B-Instruct\", token=HF_TOKEN)\n",
    "    peak = df[colname].max()\n",
    "    avg = df[colname].mean()\n",
    "    min_ = df[colname].min()\n",
    "    context = (\n",
    "        f\"PJM energy data summary:\\n\"\n",
    "        f\"- Peak: {peak:.1f} MW\\n\"\n",
    "        f\"- Average: {avg:.1f} MW\\n\"\n",
    "        f\"- Minimum: {min_:.1f} MW\\n\"\n",
    "        f\"- Data: {df.head(10).to_csv(index=False)}\\n\"\n",
    "    )\n",
    "    prompt = (\n",
    "        f\"{context}\\n\"\n",
    "        f\"User question: {question}\\n\"\n",
    "        f\"Answer in a concise, business-friendly way.\"\n",
    "    )\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    response = client.chat_completion(messages=messages, max_tokens=256, temperature=0.2)\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "def generate_hf_report(df, colname='predicted_consumption'):\n",
    "    HF_TOKEN = st.secrets[\"hf_token\"][\"hf_token\"]\n",
    "    client = InferenceClient(\"meta-llama/Meta-Llama-3-70B-Instruct\", token=HF_TOKEN)\n",
    "    peak = df[colname].max()\n",
    "    avg = df[colname].mean()\n",
    "    min_ = df[colname].min()\n",
    "    context = (\n",
    "        f\"PJM energy data summary:\\n\"\n",
    "        f\"- Peak: {peak:.1f} MW\\n\"\n",
    "        f\"- Average: {avg:.1f} MW\\n\"\n",
    "        f\"- Minimum: {min_:.1f} MW\\n\"\n",
    "        f\"- Data: {df.head(10).to_csv(index=False)}\\n\"\n",
    "    )\n",
    "    prompt = (\n",
    "        f\"{context}\\n\"\n",
    "        \"Generate a detailed business report with:\\n\"\n",
    "        \"- Executive summary\\n\"\n",
    "        \"- Key findings\\n\"\n",
    "        \"- Recommendations for energy managers\\n\"\n",
    "        \"- Any risks or opportunities\\n\"\n",
    "        \"Use clear, professional language.\"\n",
    "    )\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    response = client.chat_completion(messages=messages, max_tokens=512, temperature=0.2)\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "# --- Data Loader for Dataset Tab ---\n",
    "@st.cache_data\n",
    "def load_data():\n",
    "    if os.path.exists(\"PJMW_hourly.csv\"):\n",
    "        df = pd.read_csv(\"PJMW_hourly.csv\")\n",
    "        if 'Datetime' in df.columns and 'PJMW' in df.columns:\n",
    "            df = df.rename(columns={'Datetime':'datetime', 'PJMW':'MW'})\n",
    "        else:\n",
    "            df.columns = ['datetime', 'MW']\n",
    "        df['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')\n",
    "        df = df.dropna(subset=['datetime', 'MW'])\n",
    "        df = df.sort_values('datetime')\n",
    "        return df\n",
    "    elif os.path.exists(\"PJMW_MW_Hourly.xlsx\"):\n",
    "        df = pd.read_excel(\"PJMW_MW_Hourly.xlsx\", header=None, names=['datetime','MW'])\n",
    "        df['datetime'] = pd.to_datetime(df['datetime'].astype(str).str[:15], format='%Y-%m-%d %H%M%S', errors='coerce')\n",
    "        df['MW'] = pd.to_numeric(df['MW'], errors='coerce')\n",
    "        df = df.dropna(subset=['datetime', 'MW'])\n",
    "        df = df.sort_values('datetime')\n",
    "        return df\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# --- Tabs UI ---\n",
    "tab1, tab2 = st.tabs([\"ðŸ”® Forecast + GenAI Q&A\", \"ðŸ¤– GenAI Q&A on Dataset\"])\n",
    "\n",
    "with tab1:\n",
    "    st.markdown(\"\"\"\n",
    "    # âš¡ PJM 30-Day Forecast + GenAI Q&A\n",
    "\n",
    "    - Generate and visualize a 30-day forecast using XGBoost.\n",
    "    - Scenario analysis, peak table, automated insights, and downloadable reports.\n",
    "    - **Ask GenAI about the forecast** (business, operational, or analytical questions).\n",
    "    - Download a GenAI-powered business report.\n",
    "    ---\n",
    "    \"\"\")\n",
    "    st.sidebar.header(\"Forecast Controls (Tab 1)\")\n",
    "    start_date = st.sidebar.date_input(\"Forecast Start Date\", value=datetime.now().date())\n",
    "    start_dt = datetime.combine(start_date, datetime.min.time())\n",
    "    init_val = st.sidebar.number_input(\"Current Consumption (MW)\", value=5600.0, step=100.0)\n",
    "    mape_multiplier = st.sidebar.slider(\n",
    "        \"Adjust Uncertainty (MAPE %)\", min_value=0.5, max_value=5.0, value=float(default_mape), step=0.1,\n",
    "        help=\"Simulate higher or lower forecast uncertainty\"\n",
    "    )\n",
    "    demand_shift = st.sidebar.slider(\n",
    "        \"Adjust Demand (MW)\", min_value=-1000, max_value=1000, value=0, step=50,\n",
    "        help=\"Simulate a one-time increase or decrease in all forecasted values\"\n",
    "    )\n",
    "    if st.sidebar.button(\"ðŸ“ˆ Generate 30-Day Forecast\", use_container_width=True):\n",
    "        with st.spinner(\"Generating forecast...\"):\n",
    "            initial_lag = {\n",
    "                'lag_1h': init_val,\n",
    "                'lag_24h': init_val,\n",
    "                'lag_168h': init_val,\n",
    "                'rolling_mean_24h': init_val,\n",
    "                'rolling_std_24h': 1000.0\n",
    "            }\n",
    "            forecast_df = generate_30_day_forecast(xgb_model, start_dt, initial_lag, mape_multiplier, demand_shift)\n",
    "            st.session_state['forecast_df'] = forecast_df\n",
    "            st.success(\"âœ… Forecast generated!\")\n",
    "\n",
    "    if 'forecast_df' in st.session_state:\n",
    "        forecast_df = st.session_state['forecast_df']\n",
    "        st.subheader(\"ðŸ“ˆ 30-Day Forecast Visualization\")\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=pd.concat([forecast_df['datetime'], forecast_df['datetime'][::-1]]),\n",
    "            y=pd.concat([forecast_df['upper'], forecast_df['lower'][::-1]]),\n",
    "            fill='toself',\n",
    "            fillcolor='rgba(30,144,255,0.12)',\n",
    "            line=dict(color='rgba(255,255,255,0)'),\n",
    "            hoverinfo=\"skip\",\n",
    "            showlegend=True,\n",
    "            name='Confidence Interval'\n",
    "        ))\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=forecast_df['datetime'],\n",
    "            y=forecast_df['predicted_consumption'],\n",
    "            mode='lines',\n",
    "            name='Predicted Consumption',\n",
    "            line=dict(color='blue', width=2)\n",
    "        ))\n",
    "        fig.update_layout(\n",
    "            title=\"30-Day Hourly Energy Consumption Forecast (with Confidence Interval)\",\n",
    "            xaxis_title=\"Date\",\n",
    "            yaxis_title=\"Consumption (MW)\",\n",
    "            hovermode='x unified',\n",
    "            height=500\n",
    "        )\n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "        st.markdown(\"### ðŸ“Š Forecast Summary\")\n",
    "        col1, col2, col3, col4 = st.columns(4)\n",
    "        with col1:\n",
    "            st.metric(\"Avg MW\", f\"{forecast_df['predicted_consumption'].mean():.1f}\")\n",
    "        with col2:\n",
    "            st.metric(\"Peak MW\", f\"{forecast_df['predicted_consumption'].max():.1f}\")\n",
    "        with col3:\n",
    "            st.metric(\"Min MW\", f\"{forecast_df['predicted_consumption'].min():.1f}\")\n",
    "        with col4:\n",
    "            st.metric(\"Total GWh\", f\"{forecast_df['predicted_consumption'].sum()/1000:.1f}\")\n",
    "\n",
    "        st.markdown(\"### ðŸ”¥ Peak Demand Table\")\n",
    "        peak_table = generate_peak_table(forecast_df)\n",
    "        st.table(peak_table.style.format({'Predicted MW': '{:.1f}', 'Upper Bound': '{:.1f}', 'Lower Bound': '{:.1f}'}))\n",
    "\n",
    "        st.markdown(\"### ðŸ’¡ Automated Insights\")\n",
    "        st.info(generate_automated_insights(forecast_df, mape_multiplier))\n",
    "\n",
    "        report_text = generate_report_text(forecast_df, perf, mape_multiplier)\n",
    "        st.download_button(\n",
    "            label=\"ðŸ“„ Download Forecast Report (TXT)\",\n",
    "            data=report_text,\n",
    "            file_name=f\"pjm_30day_report_{start_date}.txt\",\n",
    "            mime=\"text/plain\"\n",
    "        )\n",
    "\n",
    "        csv = forecast_df.to_csv(index=False)\n",
    "        st.download_button(\n",
    "            label=\"ðŸ“¥ Download Forecast CSV\",\n",
    "            data=csv,\n",
    "            file_name=f\"pjm_30day_forecast_{start_date}.csv\",\n",
    "            mime=\"text/csv\"\n",
    "        )\n",
    "\n",
    "        # --- GenAI Q&A for Forecast ---\n",
    "        st.markdown(\"### ðŸ’¬ Ask GenAI about the 30-day forecast\")\n",
    "        user_question = st.text_input(\"Ask a question about the forecast (e.g., 'What is the highest demand day?')\", key=\"forecast_qa\")\n",
    "        if st.button(\"Ask GenAI\", key=\"btn_forecast_qa\"):\n",
    "            if user_question.strip():\n",
    "                with st.spinner(\"GenAI is thinking...\"):\n",
    "                    answer = ask_hf_llm(user_question, forecast_df, colname='predicted_consumption')\n",
    "                st.success(answer)\n",
    "            else:\n",
    "                st.info(\"Please enter a question.\")\n",
    "\n",
    "        # --- GenAI Automated Report ---\n",
    "        st.markdown(\"### ðŸ¤– GenAI-Powered Automated Report\")\n",
    "        if st.button(\"Download GenAI Report (TXT)\", key=\"btn_forecast_report\"):\n",
    "            with st.spinner(\"GenAI is generating your report...\"):\n",
    "                report_txt = generate_hf_report(forecast_df, colname='predicted_consumption')\n",
    "            st.download_button(\n",
    "                label=\"ðŸ“¥ Download GenAI Report\",\n",
    "                data=report_txt,\n",
    "                file_name=f\"pjm_genai_report_{start_date}.txt\",\n",
    "                mime=\"text/plain\"\n",
    "            )\n",
    "            st.success(\"GenAI report generated and ready to download!\")\n",
    "    else:\n",
    "        st.info(\"Set the start date and initial value, then click 'Generate 30-Day Forecast'.\")\n",
    "\n",
    "with tab2:\n",
    "    st.markdown(\"\"\"\n",
    "    # ðŸ¤– GenAI Q&A on Full Dataset\n",
    "\n",
    "    - Ask GenAI about any aspect of your full PJM dataset (not just the forecast).\n",
    "    - Download a business-style report for the dataset.\n",
    "    - See quick visualizations and stats.\n",
    "\n",
    "    ---\n",
    "    **Try asking GenAI questions like:**\n",
    "    - What is the highest demand day in the data?\n",
    "    - What is the average demand for July?\n",
    "    - Are there any seasonal trends or unusual patterns?\n",
    "    - How does demand change on weekends vs weekdays?\n",
    "    - When was the lowest demand recorded?\n",
    "    - Generate a summary report for the last year.\n",
    "    ---\n",
    "    \"\"\")\n",
    "    df = load_data()\n",
    "    if df is not None:\n",
    "        st.subheader(\"Data Preview\")\n",
    "        st.dataframe(df.head(48))\n",
    "        st.subheader(\"Quick Stats\")\n",
    "        st.write(df['MW'].describe())\n",
    "        st.subheader(\"Monthly Average Demand\")\n",
    "        df['month'] = df['datetime'].dt.month\n",
    "        st.bar_chart(df.groupby('month')['MW'].mean())\n",
    "\n",
    "        st.markdown(\"### ðŸ’¬ Ask GenAI about the dataset\")\n",
    "        user_question2 = st.text_input(\"Ask a question about the dataset (e.g., 'What is the highest demand day?')\", key=\"dataset_qa\")\n",
    "        if st.button(\"Ask GenAI\", key=\"btn_dataset_qa\"):\n",
    "            if user_question2.strip():\n",
    "                with st.spinner(\"GenAI is thinking...\"):\n",
    "                    answer = ask_hf_llm(user_question2, df, colname='MW')\n",
    "                st.success(answer)\n",
    "            else:\n",
    "                st.info(\"Please enter a question.\")\n",
    "\n",
    "        st.markdown(\"### ðŸ¤– GenAI-Powered Automated Report\")\n",
    "        if st.button(\"Download GenAI Dataset Report (TXT)\", key=\"btn_dataset_report\"):\n",
    "            with st.spinner(\"GenAI is generating your report...\"):\n",
    "                report_txt = generate_hf_report(df, colname='MW')\n",
    "            st.download_button(\n",
    "                label=\"ðŸ“¥ Download GenAI Report\",\n",
    "                data=report_txt,\n",
    "                file_name=f\"pjm_genai_dataset_report.txt\",\n",
    "                mime=\"text/plain\"\n",
    "            )\n",
    "            st.success(\"GenAI report generated and ready to download!\")\n",
    "    else:\n",
    "        st.warning(\"No PJM data file found. Please upload PJMW_hourly.csv or PJMW_MW_Hourly.xlsx.\")\n",
    "\n",
    "st.markdown(\"---\")\n",
    "st.markdown(\"**Powered by XGBoost + Hugging Face Llama-3 GenAI | Data Science Expert**\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631501d3-fa9f-4f9d-89f9-87c39ca7db1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3382a0-c157-4f99-becc-cbb4c834c86f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fd5bde-dc32-4ac2-8911-86333c087639",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ad48255-6b64-4fbe-bd54-edb0e3195901",
   "metadata": {},
   "source": [
    "cd \"C:\\Users\\Jeet\\DS ASSIGNMENT\\project 2\"\n",
    "\n",
    "\n",
    "streamlit run app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe8d824-ab01-42b9-9454-ef5bf497f05b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
